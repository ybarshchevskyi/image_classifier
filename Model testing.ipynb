{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing and approbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dependencies\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the checkpoint\n",
    "\n",
    "A function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, orig_mod, classifier='fc', device='cpu'): \n",
    "\n",
    "    loaded = torch.load(path, map_location=device)\n",
    "    #Define the name of fully-connected layer\n",
    "    if classifier == 'fc':\n",
    "  \n",
    "        orig_mod.fc = loaded['classifier']\n",
    "  \n",
    "    else: \n",
    "    \n",
    "        orig_mod.classifier = loaded['classifier']\n",
    "    #Freezing model parameters\n",
    "    for param in orig_mod.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    orig_mod.load_state_dict(loaded['state_dict'])\n",
    "    return orig_mod\n",
    "\n",
    "upload_model = load_model('model_flowers.pt', models.resnet50(pretrained=True), 'fc', 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing\n",
    "\n",
    "It's best to write a function that preprocesses the image so it can be used as input for the model. This function should process the images in the same manner used for training. \n",
    "\n",
    "First, the function resizes the images where the shortest side is 256 pixels, keeping the aspect ratio. This can be  Then, it crops out the center 224x224 portion of the image.\n",
    "\n",
    "Color channels of images are converted to the expected parameters of the pre-trained model -  floats 0-1. need to convert the values.\n",
    "\n",
    "As before, the network expects the images to be normalized in a specific way. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`. \n",
    "\n",
    "And finally, PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array. The color channel needs to be first and retain the order of the other two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    Process a PIL image for use in a PyTorch model\n",
    "    im = Image.open(image)\n",
    "    resized = im.resize((400,256)).crop((88,16,312,240))\n",
    "    np_image = ((np.array(resized)/255)-np.array([0.485, 0.456, 0.406]))/np.array([0.229, 0.224, 0.225])\n",
    "    image = torch.from_numpy(np.transpose(np_image, (2,1,0)))\n",
    "    return image\n",
    "  \n",
    "tensor = process_image('flower_data/train/1/image_06773.jpg')\n",
    "#print(type(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your `process_image` function works, running the output through this function should return the original image (except for the cropped out portions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax\n",
    "  \n",
    "imshow(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Prediction\n",
    "\n",
    "The function that returns k-top prediction values. It takes a path to an image and a model checkpoint, then return the probabilities and classes.\n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    image = process_image(image_path).unsqueeze_(0)\n",
    "    model.eval()\n",
    "    model.class_to_idx = train_data.class_to_idx\n",
    "    model.to('cuda')\n",
    "    output = model(image.to(device='cuda', dtype=torch.float))\n",
    "    \n",
    "    # Top probs\n",
    "    top_probs, top_labs = output.topk(topk)\n",
    "    top_probs = top_probs.detach().cpu().numpy().tolist()[0] \n",
    "    top_labs = top_labs.detach().cpu().numpy().tolist()[0]\n",
    "    \n",
    "    # Convert indices to classes\n",
    "    idx_to_class = {val: key for key, val in    \n",
    "                                      model.class_to_idx.items()}\n",
    "    top_labels = [idx_to_class[lab] for lab in top_labs]\n",
    "    top_flowers = [cat_to_name[idx_to_class[lab]] for lab in top_labs]\n",
    "    \n",
    "    return top_probs, top_labels, top_flowers\n",
    "\n",
    "prediction = predict('flower_data/train/1/image_06773.jpg', upload_model, 5)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking\n",
    "\n",
    "Function that graphs top-n probabilities distribution, along with visualization of image and its label name.\n",
    "\n",
    "<img src='assets/inference_example.png' width=300px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution(image_path, model):\n",
    "    # Set up plot\n",
    "    plt.figure(figsize = (6,10))\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    # Set up title\n",
    "    flower_num = image_path.split('/')[2]\n",
    "    title_ = cat_to_name[flower_num]\n",
    "    # Plot flower\n",
    "    img = process_image(image_path)\n",
    "    imshow(img, ax, title = title_);\n",
    "    # Make prediction\n",
    "    probs, labs, flowers = predict(image_path, model) \n",
    "    # Plot bar chart\n",
    "    plt.subplot(2,1,2)\n",
    "    sns.barplot(x=probs, y=flowers, color=sns.color_palette()[0]);\n",
    "    plt.show()\n",
    "    \n",
    "plot_solution('flower_data/train/1/image_06773.jpg', upload_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
