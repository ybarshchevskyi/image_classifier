{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHbjQhTgdRzY"
   },
   "source": [
    "# Project description\n",
    "\n",
    "This project is part of Udacity PyTorch Scholarship Challenge. More details on the scholarship could be find here - https://www.udacity.com/course/deep-learning-pytorch--ud188\n",
    "\n",
    "In this project, the task is to train an image classifier to recognize different species of flowers. Detailed dataset description is here - http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html. It consits of 102 flower categories, you can see a few examples below. \n",
    "\n",
    "<img src='assets/Flowers.png' width=500px>\n",
    "\n",
    "The project is broken down into multiple steps:\n",
    "\n",
    "* Load and preprocess the image dataset\n",
    "* Train the image classifier on your dataset\n",
    "* Use the trained classifier to predict image content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab Environment Setting\n",
    "\n",
    "Because of the complex network arhitecture, training on the CPU might take ages. The quickest and cheapest option is to use Google's new tool - Google CoLab. It provides Tesla K80 GPU 12GB for each Google account for free. In order to install all dependencies for CoLab environment, run the next cell.\n",
    "\n",
    "As an alternative, one might use any GPU with CUDA support locally or die hard and train on the CPU. In this case, ignore the next cell and jump to the imports section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "\n",
    "!pip install Pillow==4.1.1\n",
    "!pip install PIL\n",
    "!pip install image\n",
    "\n",
    "\n",
    "# workaround \n",
    "from PIL import Image\n",
    "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
    "Image.register_extension = register_extension\n",
    "def register_extensions(id, extensions): \n",
    "    for extension in extensions: \n",
    "        register_extension(id, extension)\n",
    "Image.register_extensions = register_extensions\n",
    "\n",
    "#Mounting Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "\n",
    "#Moving to the flowers directory (might be different for your file structure)\n",
    "%cd ../\n",
    "%cd 'gdrive/My Drive/Flowers'\n",
    "%cd 'Flowers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14812,
     "status": "ok",
     "timestamp": 1543755069451,
     "user": {
      "displayName": "Yevhen Barshchevskyi",
      "photoUrl": "",
      "userId": "04846144195558080739"
     },
     "user_tz": -120
    },
    "id": "MziVFCR5dRzd",
    "outputId": "0ed6a8db-7d98-4223-9dbc-db0c26bf7b57"
   },
   "outputs": [],
   "source": [
    "# Loading dependencies for the project \n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cA4Ye7x_dRzt"
   },
   "source": [
    "## Load the data\n",
    "\n",
    "Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). You can [download the data here](https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip). The dataset is split into two parts, training and validation. For the training, one needs to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. We would use pre-trained network (transfer learning), thus, the input data should be resized to 224x224 pixels as required by the networks.\n",
    "\n",
    "The validation set is used to measure the model's performance on data it hasn't seen yet. The only transformations needed is that each image should be cropped to 224x224 pixels.\n",
    "\n",
    "The pre-trained networks available from `torchvision` were trained on the ImageNet dataset where each color channel was normalized separately. For both sets we need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fhuOuHSmdRz7"
   },
   "outputs": [],
   "source": [
    "#Data path (might be different for your file structure)\n",
    "data_dir = 'flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezOTLOQYdR0H"
   },
   "outputs": [],
   "source": [
    "# Defining transforms for the training and validation sets\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(15), \n",
    "                                      transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(p=0.1),\n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# Loading the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
    "\n",
    "# Using the image datasets and the trainforms, define the dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xh4VLwZpdR0O"
   },
   "source": [
    "### Label mapping\n",
    "\n",
    "Category label is mapped to category name in the JSON file - `cat_to_name.json`. This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJSCz9rAdR0Q"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kq2bK8jvdR0Y"
   },
   "source": [
    "# Building and training the classifier\n",
    "\n",
    "The easiest way to complete this task is to use a pre-trained models from `torchvision.models` to get the image features. \n",
    "\n",
    "* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html)\n",
    "* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
    "* Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
    "* Track the loss and accuracy on the validation set to determine the best hyperparameters\n",
    "\n",
    "Provided example uses ResNet50 model, which gives you \"7.13%\" error for top-5 classes. In other words, the model will correctly predict \"92.87%\" of the image classification task. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5863
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5119,
     "status": "ok",
     "timestamp": 1543755201179,
     "user": {
      "displayName": "Yevhen Barshchevskyi",
      "photoUrl": "",
      "userId": "04846144195558080739"
     },
     "user_tz": -120
    },
    "id": "4osuqrpDdR0Z",
    "outputId": "8155866c-7cd4-443c-c849-12a485a67919"
   },
   "outputs": [],
   "source": [
    "#Loading pre-trained model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iy5hfW8ndR0n"
   },
   "outputs": [],
   "source": [
    "# Freeze parameters. This is important step. All parameters for features should be freezed. \n",
    "#Otherwise, the model will be changing gradients of features at each epoch. \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "#Loading new layers to the trained model\n",
    "#This is the layers I used for the training. It couldbe changed in different ways.\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(2048, 512)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('drop', nn.Dropout(p=0.5)),\n",
    "                          ('fc2', nn.Linear(512, 256)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('drop', nn.Dropout(p=0.5)),\n",
    "                          ('fc3', nn.Linear(256, 102)),\n",
    "                          ]))\n",
    "#Adding your layer to the model as the fully-connected layer    \n",
    "model.fc = classifier\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tq4kvHCCdR0p"
   },
   "outputs": [],
   "source": [
    "# specify loss function (I used categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (needed to compute backward propagation)\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 96
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3753,
     "status": "ok",
     "timestamp": 1543755231726,
     "user": {
      "displayName": "Yevhen Barshchevskyi",
      "photoUrl": "",
      "userId": "04846144195558080739"
     },
     "user_tz": -120
    },
    "id": "ORxr1FtheuL2",
    "outputId": "988bc8e0-c569-48ac-9140-07a69fe15e13"
   },
   "outputs": [],
   "source": [
    "# Use GPU if it's available (if CUDA is available, run on CUDA)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdBtBHcIBZNv"
   },
   "outputs": [],
   "source": [
    "#Defining your checkpoint information. Checkpoint is used to save your model during each epoch.\n",
    "model.class_to_idx = train_data.class_to_idx\n",
    "checkpoint = OrderedDict({'input_size': 2048,\n",
    "              'output_size': 102,\n",
    "              'epoch': 0,\n",
    "              'classifier':classifier,\n",
    "              'ind': model.class_to_idx,\n",
    "              'state_dict': model.state_dict(),\n",
    "              'optim': optimizer.state_dict()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VGID4G3IdR0r"
   },
   "outputs": [],
   "source": [
    "#Training part. This cell will run the model through n-number of epochs. Each epoch will print the following statistics:\n",
    "#Epoch -- Training loss -- Validation loss -- Validation accuracy -- Duration of each epoch\n",
    "\n",
    "from datetime import datetime\n",
    "# number of epochs to train the model\n",
    "n_epochs = 25\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    start_time = datetime.now()\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    # keep track of accuracy for the validation set\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in trainloader:\n",
    "        # enable CUDA\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in validloader: \n",
    "        # enable CUDA\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "    valid_loss = valid_loss/len(validloader.dataset)\n",
    "    \n",
    "    #calculate average accuracy\n",
    "    _, top_class = torch.max(output, 1)\n",
    "    total += target.size(0)\n",
    "    correct += (top_class == target).sum().item()\n",
    "    end_time = datetime.now() \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tAccuracy: {} \\tDuration: {}'.format(epoch, train_loss, valid_loss, (correct/total),(end_time - start_time)))\n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "        checkpoint['state_dict'] = model.state_dict()\n",
    "        checkpoint['optim'] = optimizer.state_dict()\n",
    "        checkpoint['epoch'] = epoch\n",
    "        torch.save(checkpoint, 'model_flowers2.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Image Classifier Project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
